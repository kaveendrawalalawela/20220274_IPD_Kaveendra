# -*- coding: utf-8 -*-
"""FYP - FINALipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r7UTP4VwTQbLFTIipsSGtJzIRubM4jnL
"""

from google.colab import drive
drive.mount('/content/drive')

"""Scan for Colombo CSV Files"""

import os

# Define the directory to search within your mounted Google Drive
drive_path = '/content/drive/My Drive/'

# Find all CSV files recursively within the drive
all_csv_files = []
for root, dirs, files in os.walk(drive_path):
    for file in files:
        if file.endswith('.csv'):
            all_csv_files.append(os.path.join(root, file))

# Filter for files containing 'colombo' in their name (case-insensitive)
colombo_files = [f for f in all_csv_files if 'colombo' in os.path.basename(f).lower()]

print(f"Found {len(colombo_files)} Colombo CSV files\n")
for f in sorted(colombo_files):
    print(f"  {f}")

"""Load All CSV Files"""

import pandas as pd
import warnings
warnings.filterwarnings('ignore')

print("="*70)
print("CELL 1b: LOAD ALL CSV FILES")
print("="*70)

# Load each file
all_data = []
print()
for filename in sorted(colombo_files):
    df = pd.read_csv(filename)

    # Extract region number (01, 02, 03, 04)
    parts = filename.replace('.csv', '').split()
    region_num = None
    year_num = None

    for part in parts:
        if part.isdigit() and len(part) == 2:
            region_num = part
        elif part.isdigit() and len(part) == 4:
            year_num = int(part)

    # Add metadata
    df['region'] = f'Colombo {region_num}'
    df['year'] = year_num

    all_data.append(df)
    print(f"‚úÖ {filename}: {len(df)} records")

print("\n" + "="*70)

"""Combine All Data"""

print("="*70)
print("CELL 1c: COMBINE ALL DATA")
print("="*70)

# Combine all dataframes
df_combined = pd.concat(all_data, ignore_index=True)

print(f"\nTotal records: {len(df_combined):,}")
print(f"Regions: {sorted(df_combined['region'].unique())}")
print(f"Years: {sorted(df_combined['year'].unique())}")

# Check coverage
print("\nData coverage by region and year:")
coverage = df_combined.groupby(['region', 'year']).size().reset_index(name='records')
for _, row in coverage.sort_values(['region', 'year']).iterrows():
    print(f"  {row['region']} {row['year']}: {row['records']} records")

print("\n" + "="*70)

"""Clean and Prepare Data"""

print("="*70)
print("CELL 2: CHECK AVAILABLE VARIABLES")
print("="*70)

# Show all column names
print(f"\nTotal columns: {len(df_combined.columns)}")
print("\nAll variables in dataset:")
for i, col in enumerate(df_combined.columns, 1):
    print(f"  {i:2d}. {col}")

# Show sample of first row
print("\nSample data (first record):")
print(df_combined.iloc[0])

print("\n" + "="*70)

"""Correlation Analysis"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

print("="*70)
print("CELL 3: CORRELATION ANALYSIS WITH SOLAR ENERGY")
print("="*70)

# Select only numeric columns for correlation
numeric_cols = df_combined.select_dtypes(include=[np.number]).columns.tolist()

# Remove non-weather variables
exclude_cols = ['year', 'severerisk', 'moonphase', 'winddir']
numeric_cols = [col for col in numeric_cols if col not in exclude_cols]

# Calculate correlation with solarenergy
correlations = df_combined[numeric_cols].corr()['solarenergy'].sort_values(ascending=False)

print("\nCorrelation with Solar Energy:")
print("="*70)
for var, corr in correlations.items():
    if var != 'solarenergy':
        if abs(corr) > 0.7:
            strength = "‚úÖ VERY STRONG"
        elif abs(corr) > 0.5:
            strength = "‚úÖ STRONG"
        elif abs(corr) > 0.3:
            strength = "‚ö†Ô∏è  MODERATE"
        else:
            strength = "‚ùå WEAK"
        print(f"  {var:20s} {corr:>+.4f}  {strength}")

"""Visual to show corelation"""

import matplotlib.pyplot as plt

print("="*70)
print("CELL 4d: SOLAR ENERGY CORRELATION BAR CHART")
print("="*70)

# Get correlation with solar energy (already calculated earlier)
solar_corr = correlations.drop('solarenergy').sort_values(key=abs, ascending=True)

# Create horizontal bar chart
plt.figure(figsize=(10, 8))
colors = ['green' if x > 0 else 'red' for x in solar_corr.values]
plt.barh(solar_corr.index, solar_corr.values, color=colors, alpha=0.7, edgecolor='black')

# Add threshold lines
plt.axvline(x=0.4, color='blue', linestyle='--', linewidth=2, label='Threshold (+0.4)')
plt.axvline(x=-0.4, color='blue', linestyle='--', linewidth=2, label='Threshold (-0.4)')
plt.axvline(x=0, color='black', linestyle='-', linewidth=1)

plt.xlabel('Correlation Coefficient (r)', fontsize=12, fontweight='bold')
plt.ylabel('Weather Variables', fontsize=12, fontweight='bold')
plt.title('Correlation with Solar Energy (All Variables)',
          fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig('Solar_Energy_Correlation_Bar.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Saved: Solar_Energy_Correlation_Bar.png")
plt.show()

print("\n" + "="*70)

print("CELL 4a: IDENTIFY VARIABLES ABOVE CORRELATION THRESHOLD")


# Set threshold
threshold = 0.4

# Get correlations above threshold (excluding solarenergy itself)
strong_vars = correlations[
    (correlations.abs() > threshold) &
    (correlations.index != 'solarenergy')
].sort_values(key=abs, ascending=False)

print(f"\nVariables with |r| > {threshold}:")
print("-"*70)
for var, corr in strong_vars.items():
    print(f"  {var:20s} {corr:>+.4f}")

print(f"\nTotal: {len(strong_vars)} variables pass threshold")

"""Remove Redundant Variables"""

print("CELL 4b: REMOVE REDUNDANT VARIABLES")


print("\nüìã DECISION LOGIC:")


# Variables that passed threshold
passed_vars = strong_vars.index.tolist()

# Variables to EXCLUDE (with reasons)
exclude_vars = {
    'solarradiation': 'Too similar to target (r=0.9997 - multicollinearity)',
    'tempmax': 'Redundant with temp (both measure temperature)',
    'feelslikemax': 'Derived from temp + humidity (redundant)',
    'feelslike': 'Derived from temp + humidity (redundant)'
}

# Variables to KEEP
keep_vars = [var for var in passed_vars if var not in exclude_vars]

print("\n‚ùå EXCLUDED Variables:")
for var, reason in exclude_vars.items():
    if var in passed_vars:
        print(f"  {var:20s} - {reason}")

print("\n‚úÖ FINAL SELECTED PREDICTORS:")
print("-"*70)
for var in keep_vars:
    corr_val = correlations[var]
    print(f"  {var:20s} {corr_val:>+.4f}")

print(f"\nTotal predictors: {len(keep_vars)}")

"""Create Final Dataset with Selected Variables"""

print("="*70)
print("CELL 4c: CREATE FINAL DATASET")
print("="*70)

# Create list of columns to keep
final_columns = [
    'datetime',
    'region',
    'year',
    'solarenergy',    # Target
    'uvindex',        # Predictor 1
    'humidity',       # Predictor 2
    'cloudcover',     # Predictor 3
    'temp',           # Predictor 4
    'precipcover'     # Predictor 5
]

# Create final dataset
df_final = df_combined[final_columns].copy()

# Convert datetime
df_final['datetime'] = pd.to_datetime(df_final['datetime'], format='mixed')

# Remove any missing values
df_final = df_final.dropna()

print(f"\n‚úÖ Final dataset created")
print(f"   Shape: {df_final.shape[0]:,} records √ó {df_final.shape[1]} columns")
print(f"   Date range: {df_final['datetime'].min()} to {df_final['datetime'].max()}")
print(f"   Regions: {sorted(df_final['region'].unique())}")
print(f"   Years: {sorted(df_final['year'].unique())}")

print("\nüìä Variables in final dataset:")
for i, col in enumerate(final_columns, 1):
    print(f"   {i}. {col}")

print("\n" + "="*70)

"""Spatial Analysis - Compare Regions"""

from scipy import stats

print("CELL 5: SPATIAL ANALYSIS - COMPARE REGIONS")

# Group by region
regions = sorted(df_final['region'].unique())

print(f"\nRegions to compare: {regions}")

# Calculate mean solar energy by region
print("\nüìä Mean Solar Energy by Region:")
print("-"*70)
for region in regions:
    region_data = df_final[df_final['region'] == region]['solarenergy']
    print(f"  {region}: {region_data.mean():.2f} MJ/m¬≤ (n={len(region_data)} records)")

# ANOVA test - are means significantly different?
region_groups = [df_final[df_final['region'] == r]['solarenergy'].values
                 for r in regions]

f_stat, p_value = stats.f_oneway(*region_groups)

print("\nüìà ANOVA TEST RESULTS:")
print("-"*70)
print(f"  F-statistic: {f_stat:.4f}")
print(f"  p-value: {p_value:.4f}")
print(f"  Significance level: Œ± = 0.05")

if p_value < 0.05:
    print("\n‚ùå RESULT: SIGNIFICANT DIFFERENCE (p < 0.05)")
    print("   ‚Üí Regions have statistically different solar energy")
else:
    print("\n‚úÖ RESULT: NO SIGNIFICANT DIFFERENCE (p > 0.05)")
    print("   ‚Üí Regions are statistically similar")
    print("   ‚Üí Justified to use single representative location")

print("\n" + "="*70)

print("CELL 6: FILTER TO COLOMBO 04 ONLY")


# Filter to Colombo 04 only
df_colombo04 = df_final[df_final['region'] == 'Colombo 04'].copy()

# Reset index
df_colombo04 = df_colombo04.reset_index(drop=True)

# Sort by date
df_colombo04 = df_colombo04.sort_values('datetime').reset_index(drop=True)

print(f"\n‚úÖ Filtered to Colombo 04")
print(f"   Records: {len(df_colombo04):,}")
print(f"   Date range: {df_colombo04['datetime'].min()} to {df_colombo04['datetime'].max()}")
print(f"   Years: {sorted(df_colombo04['year'].unique())}")

# Check data completeness
print("\nüìä Data by year:")
year_counts = df_colombo04.groupby('year').size()
for year, count in year_counts.items():
    print(f"   {year}: {count} records")

print("\n" + "="*70)

"""Double checking the variables"""

print("="*70)
print("CELL 7b: CHECK VARIABLES IN COLOMBO 04 DATASET")
print("="*70)

print(f"\nTotal columns: {len(df_colombo04.columns)}")
print("\nVariables in Colombo 04 dataset:")
for i, col in enumerate(df_colombo04.columns, 1):
    print(f"  {i}. {col}")

print("\nüìä Sample data (first 3 rows):")
print(df_colombo04.head(3))

print("\nüìà Data types:")
print(df_colombo04.dtypes)

print("\n" + "="*70)

"""Feature Engineering

Extracting year and month
"""

# Extract year and month from datetime
df_colombo04['year'] = df_colombo04['datetime'].dt.year
df_colombo04['month'] = df_colombo04['datetime'].dt.month

print(df_colombo04[['datetime', 'year', 'month']].head())

"""Group by Year and Month"""

# Group by year and month
monthly_grouped = df_colombo04.groupby(['year', 'month'])

print(f"\n‚úÖ Created {len(monthly_grouped)} monthly groups")

# Show how many records in each group
print("\n Records per month:")
group_counts = monthly_grouped.size().reset_index(name='daily_records')
print(group_counts.head(12))  # Show first 12 months

"""Calculate Monthly Averages"""

print("CELL 8c: CALCULATE MONTHLY AVERAGES")


# Calculate monthly aggregations
monthly_data = df_colombo04.groupby(['year', 'month']).agg({
    'solarenergy': 'mean',
    'uvindex': 'mean',
    'cloudcover': 'mean',
    'humidity': 'mean',
    'temp': 'mean',
    'precipcover': 'sum'
}).reset_index()

print(f"   Total months: {len(monthly_data)}")

print("\nüìä Aggregation methods:")
print("   solarenergy  ‚Üí MEAN")
print("   uvindex      ‚Üí MEAN")
print("   cloudcover   ‚Üí MEAN")
print("   humidity     ‚Üí MEAN")
print("   temp         ‚Üí MEAN")
print("   precipcover  ‚Üí SUM")

print("\nFirst 5 months:")
print(monthly_data.head())

"""Create Date Column"""

print("CELL 8d: CREATE DATE COLUMN")


# Create date column (first day of each month)
monthly_data['date'] = pd.to_datetime(monthly_data[['year', 'month']].assign(day=1))

print("\n‚úÖ Date column created")

print("\nDataset preview:")
print(monthly_data[['date', 'year', 'month', 'solarenergy']].head())

print(f"\nDate range: {monthly_data['date'].min()} to {monthly_data['date'].max()}")

print("\n" + "="*70)

print("="*70)
print("CELL 9: ADD SRI LANKAN MONSOON SEASONS")
print("="*70)

# Define season assignment function
def assign_season(month):
    if month in [12, 1, 2]:
        return 'NE Monsoon'
    elif month in [3, 4]:
        return 'Inter-Monsoon 1'
    elif month in [5, 6, 7, 8, 9]:
        return 'SW Monsoon'
    else:  # 10, 11
        return 'Inter-Monsoon 2'

# Apply season assignment
monthly_data['season'] = monthly_data['month'].apply(assign_season)

print("\n‚úÖ Monsoon seasons added")

print("\nüå¶Ô∏è Season definitions:")
print("   NE Monsoon       (Dec-Feb)")
print("   Inter-Monsoon 1  (Mar-Apr)")
print("   SW Monsoon       (May-Sep)")
print("   Inter-Monsoon 2  (Oct-Nov)")

print("\nDataset preview:")
print(monthly_data[['date', 'month', 'season', 'solarenergy']].head(12))

print(f"\nüìä Records by season:")
season_counts = monthly_data['season'].value_counts()
for season, count in season_counts.items():
    print(f"   {season:20s} {count} months")

print("\n" + "="*70)

# Set season order
season_order = ['NE Monsoon', 'Inter-Monsoon 1', 'SW Monsoon', 'Inter-Monsoon 2']

# Create box plot
plt.figure(figsize=(12, 6))
sns.boxplot(data=monthly_data, x='season', y='solarenergy',
            order=season_order, palette='Set2')

plt.xlabel('Monsoon Season', fontsize=12, fontweight='bold')
plt.ylabel('Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
plt.title('Solar Energy Distribution by Sri Lankan Monsoon Season',
          fontsize=14, fontweight='bold')
plt.xticks(rotation=15)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('Solar_Energy_by_Monsoon_Season.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Saved: Solar_Energy_by_Monsoon_Season.png")
plt.show()

"""Save Clean Monthly Dataset"""

print("CELL 10: SAVE CLEAN MONTHLY DATASET")


# Save to CSV
monthly_data.to_csv('monthly_dataset_colombo04.csv', index=False)

print("\n‚úÖ Dataset saved: monthly_dataset_colombo04.csv")

print(f"\nüìä Final dataset summary:")
print(f"   Records: {len(monthly_data)}")
print(f"   Variables: {len(monthly_data.columns)}")
print(f"   Date range: {monthly_data['date'].min().date()} to {monthly_data['date'].max().date()}")

print("\nüìã Variables in dataset:")
for i, col in enumerate(monthly_data.columns, 1):
    print(f"   {i}. {col}")

"""# ***Exploratory Data Analysis***

Monthly Solar Energy Time Series
"""

import matplotlib.pyplot as plt


# Calculate basic statistics
mean_solar = monthly_data['solarenergy'].mean()
min_solar = monthly_data['solarenergy'].min()
max_solar = monthly_data['solarenergy'].max()

print(f"\nüìä Solar Energy Statistics:")
print(f"   Mean:  {mean_solar:.2f} MJ/m¬≤")
print(f"   Min:   {min_solar:.2f} MJ/m¬≤")
print(f"   Max:   {max_solar:.2f} MJ/m¬≤")
print(f"   Range: {max_solar - min_solar:.2f} MJ/m¬≤")

# Create time series plot
plt.figure(figsize=(14, 6))
plt.plot(monthly_data['date'], monthly_data['solarenergy'],
         'o-', linewidth=2, markersize=5, color='orange', alpha=0.8)
plt.axhline(y=mean_solar, color='red', linestyle='--',
            linewidth=2, alpha=0.7, label=f'Mean: {mean_solar:.2f} MJ/m¬≤')

plt.xlabel('Date', fontsize=12, fontweight='bold')
plt.ylabel('Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
plt.title('Monthly Solar Energy - Colombo 04 (2021-2025)',
          fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('Monthly_Solar_Energy_Timeseries.png', dpi=300, bbox_inches='tight')
print("\n‚úÖ Saved: Monthly_Solar_Energy_Timeseries.png")
plt.show()

"""Monthly Patterns (Jan-Dec)"""

# Calculate average solar energy for each calendar month
monthly_avg = monthly_data.groupby('month')['solarenergy'].mean().sort_index()

month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

print("\nüìä Average Solar Energy by Month:")

for month, avg in monthly_avg.items():
    print(f"   {month_names[month-1]:3s}: {avg:.2f} MJ/m¬≤")

# Find highest and lowest months
max_month = monthly_avg.idxmax()
min_month = monthly_avg.idxmin()

print(f"\n‚òÄÔ∏è  Highest: {month_names[max_month-1]} ({monthly_avg[max_month]:.2f} MJ/m¬≤)")
print(f"‚òÅÔ∏è  Lowest:  {month_names[min_month-1]} ({monthly_avg[min_month]:.2f} MJ/m¬≤)")

# Create bar chart
plt.figure(figsize=(12, 6))
bars = plt.bar(range(1, 13), monthly_avg.values, color='orange',
               alpha=0.7, edgecolor='black', linewidth=1.5)

# Highlight highest and lowest
bars[max_month-1].set_color('green')
bars[min_month-1].set_color('red')

plt.xlabel('Month', fontsize=12, fontweight='bold')
plt.ylabel('Average Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
plt.title('Average Solar Energy by Month (2021-2025)',
          fontsize=14, fontweight='bold')
plt.xticks(range(1, 13), month_names)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('Monthly_Pattern_Jan_Dec.png', dpi=300, bbox_inches='tight')
plt.show()

"""Year-over-Year Comparison"""

# Calculate average solar energy by year
yearly_avg = monthly_data.groupby('year')['solarenergy'].agg(['mean', 'std', 'count'])

print("\nüìä Solar Energy by Year:")
for year, row in yearly_avg.iterrows():
    print(f"   {year}: Mean = {row['mean']:.2f} MJ/m¬≤  "
          f"Std = {row['std']:.2f}  Months = {int(row['count'])}")

# Create line plot for each year
plt.figure(figsize=(14, 6))

for year in sorted(monthly_data['year'].unique()):
    year_data = monthly_data[monthly_data['year'] == year].sort_values('month')
    plt.plot(year_data['month'], year_data['solarenergy'],
             'o-', linewidth=2, markersize=6, label=str(year), alpha=0.8)

plt.xlabel('Month', fontsize=12, fontweight='bold')
plt.ylabel('Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
plt.title('Year-over-Year Comparison (2021-2025)',
          fontsize=14, fontweight='bold')
plt.xticks(range(1, 13), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
plt.legend(title='Year', fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('Year_over_Year_Comparison.png', dpi=300, bbox_inches='tight')
plt.show()

"""Distribution Analysis"""

# Calculate distribution statistics
mean = monthly_data['solarenergy'].mean()
median = monthly_data['solarenergy'].median()
std = monthly_data['solarenergy'].std()
skewness = monthly_data['solarenergy'].skew()

print("\n Distribution Statistics:")
print(f"   Mean:     {mean:.2f} MJ/m¬≤")
print(f"   Median:   {median:.2f} MJ/m¬≤")
print(f"   Std Dev:  {std:.2f} MJ/m¬≤")
print(f"   Skewness: {skewness:.3f}")

if abs(skewness) < 0.5:
    print("   ‚Üí Distribution is approximately symmetric")
elif skewness > 0:
    print("   ‚Üí Distribution is right-skewed (positive skew)")
else:
    print("   ‚Üí Distribution is left-skewed (negative skew)")

# Create histogram
plt.figure(figsize=(10, 6))
plt.hist(monthly_data['solarenergy'], bins=15,
         color='skyblue', edgecolor='black', alpha=0.7)
plt.axvline(x=mean, color='red', linestyle='--',
            linewidth=2, label=f'Mean: {mean:.2f}')
plt.axvline(x=median, color='green', linestyle='--',
            linewidth=2, label=f'Median: {median:.2f}')

plt.xlabel('Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
plt.ylabel('Frequency', fontsize=12, fontweight='bold')
plt.title('Distribution of Monthly Solar Energy',
          fontsize=14, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.savefig('Solar_Energy_Distribution.png', dpi=300, bbox_inches='tight')
plt.show()

"""Autocorrelation Analysis - Solar Energy"""

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
import matplotlib.pyplot as plt

# Create ACF and PACF plots
fig, axes = plt.subplots(2, 1, figsize=(12, 10))

# Plot ACF
plot_acf(monthly_data['solarenergy'], lags=12, ax=axes[0], alpha=0.05)
axes[0].set_title('Autocorrelation Function (ACF) - Solar Energy',
                  fontsize=13, fontweight='bold')
axes[0].set_xlabel('Lag (months)', fontsize=11, fontweight='bold')
axes[0].set_ylabel('Correlation', fontsize=11, fontweight='bold')
axes[0].grid(True, alpha=0.3)

# Plot PACF
plot_pacf(monthly_data['solarenergy'], lags=12, ax=axes[1], alpha=0.05)
axes[1].set_title('Partial Autocorrelation Function (PACF) - Solar Energy',
                  fontsize=13, fontweight='bold')
axes[1].set_xlabel('Lag (months)', fontsize=11, fontweight='bold')
axes[1].set_ylabel('Correlation', fontsize=11, fontweight='bold')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('ACF_PACF_Solar_Energy.png', dpi=300, bbox_inches='tight')
print("\n Saved: ACF_PACF_Solar_Energy.png")
plt.show()

print("\n INTERPRETATION GUIDE:")
print("   Blue shaded area = 95% confidence interval")
print("   Bars outside blue = Statistically significant correlation")
print("   Lag 1 = correlation with 1 month ago")
print("   Lag 12 = correlation with same month last year")

from statsmodels.tsa.stattools import adfuller

# Perform Augmented Dickey-Fuller test
adf_result = adfuller(monthly_data['solarenergy'])

print("\n AUGMENTED DICKEY-FULLER TEST:")
print("-"*70)
print(f"   ADF Statistic:  {adf_result[0]:.4f}")
print(f"   p-value:        {adf_result[1]:.4f}")
print(f"\n   Critical Values:")
for key, value in adf_result[4].items():
    print(f"      {key:>4s}: {value:.4f}")

# Interpretation
print("\n INTERPRETATION:")
print("-"*70)
if adf_result[1] < 0.05:
    print(f"    p-value ({adf_result[1]:.4f}) < 0.05")
    print("   \u2192 REJECT null hypothesis")
    print("   \u2192 Time series is STATIONARY")
    print("   \u2192 Mean and variance are constant over time")
    print("   \u2192  Suitable for regression-based forecasting")
else:
    print(f"     p-value ({adf_result[1]:.4f}) > 0.05")
    print("   \u2192 FAIL TO REJECT null hypothesis")
    print("   \u2192 Time series is NON-STATIONARY")
    print("   \u2192 Contains trend or significant seasonality")

"""# ***Machine Learning Model Development***

Define Features and Target
"""

# Define features (predictors)
feature_columns = ['uvindex', 'cloudcover', 'humidity', 'temp', 'precipcover']

# Define target (what we predict)
target_column = 'solarenergy'

print("\n Features (X):")
for i, col in enumerate(feature_columns, 1):
    print(f"   {i}. {col}")

print(f"\n Target (y): {target_column}")

# Create feature matrix (X)
X = monthly_data[feature_columns]

# Create target vector (y)
y = monthly_data[target_column]

print(f"\n‚úÖ X (Features):")
print(f"   Shape: {X.shape[0]} rows √ó {X.shape[1]} columns")
print("\nFirst 3 rows:")
print(X.head(3))

print(f"\n‚úÖ y (Target):")
print(f"   Shape: {y.shape[0]} values")
print("\nFirst 3 values:")
print(y.head(3))

"""Split into Training and Testing Sets"""

from sklearn.model_selection import train_test_split
# Split data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

print("\n Data split complete")
print(f"\n Training set:")
print(f"   X_train: {X_train.shape[0]} samples")
print(f"   y_train: {y_train.shape[0]} samples")

print(f"\n Testing set:")
print(f"   X_test: {X_test.shape[0]} samples")
print(f"   y_test: {y_test.shape[0]} samples")

print(f"\n Split ratio:")
print(f"   Training: {len(X_train)/len(X)*100:.1f}%")
print(f"   Testing:  {len(X_test)/len(X)*100:.1f}%")

"""**Train Linear Regression Model**

Initialize Linear Regression Model
"""

from sklearn.linear_model import LinearRegression

# Create model
model_lr = LinearRegression()

print("\n Linear Regression model initialized")

"""Train Linear Regression"""

# Train model on training data
model_lr.fit(X_train, y_train)

print("\n Model training complete")
print(f"   Trained on {len(X_train)} samples")
print(f"   Using {X_train.shape[1]} features")

"""Make Predictions"""

# Predict on training set
y_pred_train = model_lr.predict(X_train)

# Predict on testing set
y_pred_test = model_lr.predict(X_test)

print("\n Predictions generated")
print(f"   Training predictions: {len(y_pred_train)}")
print(f"   Testing predictions: {len(y_pred_test)}")

print("\nFirst 3 predictions (test set):")
for i in range(min(3, len(y_test))):
    print(f"   Actual: {y_test.iloc[i]:.2f} MJ/m¬≤  ‚Üí  Predicted: {y_pred_test[i]:.2f} MJ/m¬≤")

"""Calculate Performance Metrics"""

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np


# Training metrics
train_r2 = r2_score(y_train, y_pred_train)
train_mae = mean_absolute_error(y_train, y_pred_train)
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))

# Testing metrics
test_r2 = r2_score(y_test, y_pred_test)
test_mae = mean_absolute_error(y_test, y_pred_test)
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("\n LINEAR REGRESSION PERFORMANCE:")
print(f"   TRAINING SET:")
print(f"      R¬≤   = {train_r2:.4f}")
print(f"      MAE  = {train_mae:.3f} MJ/m¬≤")
print(f"      RMSE = {train_rmse:.3f} MJ/m¬≤")

print(f"\n   TESTING SET:")
print(f"      R¬≤   = {test_r2:.4f}")
print(f"      MAE  = {test_mae:.3f} MJ/m¬≤")
print(f"      RMSE = {test_rmse:.3f} MJ/m¬≤")

print(f"\n   Overfitting gap: {train_r2 - test_r2:.4f}")

"""**Initialize Decision Tree Model**"""

from sklearn.tree import DecisionTreeRegressor


# Create Decision Tree model
model_dt = DecisionTreeRegressor(
    max_depth=5,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42
)

print("\n Decision Tree model initialized")
print("   Parameters:")
print("      max_depth = 5")
print("      min_samples_split = 5")
print("      min_samples_leaf = 2")

"""Train Decision Tree Model"""

# Train model
model_dt.fit(X_train, y_train)

print("\n Decision Tree training complete")
print(f" Trained on {len(X_train)} samples")

# Make predictions
y_pred_train_dt = model_dt.predict(X_train)
y_pred_test_dt = model_dt.predict(X_test)

# Calculate metrics
train_r2_dt = r2_score(y_train, y_pred_train_dt)
train_mae_dt = mean_absolute_error(y_train, y_pred_train_dt)
train_rmse_dt = np.sqrt(mean_squared_error(y_train, y_pred_train_dt))

test_r2_dt = r2_score(y_test, y_pred_test_dt)
test_mae_dt = mean_absolute_error(y_test, y_pred_test_dt)
test_rmse_dt = np.sqrt(mean_squared_error(y_test, y_pred_test_dt))

print("\n DECISION TREE PERFORMANCE:")

print(f"   TRAINING SET:")
print(f"      R¬≤   = {train_r2_dt:.4f}")
print(f"      MAE  = {train_mae_dt:.3f} MJ/m¬≤")
print(f"      RMSE = {train_rmse_dt:.3f} MJ/m¬≤")

print(f"\n   TESTING SET:")
print(f"      R¬≤   = {test_r2_dt:.4f}")
print(f"      MAE  = {test_mae_dt:.3f} MJ/m¬≤")
print(f"      RMSE = {test_rmse_dt:.3f} MJ/m¬≤")

print(f"\n   Overfitting gap: {train_r2_dt - test_r2_dt:.4f}")

"""Initialize Random Forest Model"""

from sklearn.ensemble import RandomForestRegressor


# Create Random Forest model
model_rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=5,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

print("\n Random Forest model initialized")
print("   Parameters:")
print("   n_estimators = 100")
print("   max_depth = 5")
print("   min_samples_split = 5")

"""Train Random Forest Model"""

# Train model
model_rf.fit(X_train, y_train)

print("\n Random Forest training complete")
print(f"  Trained 100 trees on {len(X_train)} samples")

"""Random Forest Predictions & Metrics"""

# Make predictions
y_pred_train_rf = model_rf.predict(X_train)
y_pred_test_rf = model_rf.predict(X_test)

# Calculate metrics
train_r2_rf = r2_score(y_train, y_pred_train_rf)
train_mae_rf = mean_absolute_error(y_train, y_pred_train_rf)
train_rmse_rf = np.sqrt(mean_squared_error(y_train, y_pred_train_rf))

test_r2_rf = r2_score(y_test, y_pred_test_rf)
test_mae_rf = mean_absolute_error(y_test, y_pred_test_rf)
test_rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_test_rf))

print("\n RANDOM FOREST PERFORMANCE:")
print(f"   TRAINING SET:")
print(f"      R¬≤   = {train_r2_rf:.4f}")
print(f"      MAE  = {train_mae_rf:.3f} MJ/m¬≤")
print(f"      RMSE = {train_rmse_rf:.3f} MJ/m¬≤")

print(f"\n   TESTING SET:")
print(f"      R¬≤   = {test_r2_rf:.4f}")
print(f"      MAE  = {test_mae_rf:.3f} MJ/m¬≤")
print(f"      RMSE = {test_rmse_rf:.3f} MJ/m¬≤")

print(f"\n   Overfitting gap: {train_r2_rf - test_r2_rf:.4f}")

"""Initialize Gradient Boosting Model"""

from sklearn.ensemble import GradientBoostingRegressor

# Create Gradient Boosting model
model_gb = GradientBoostingRegressor(
    n_estimators=100,
    max_depth=4,
    learning_rate=0.1,
    random_state=42
)

print("\n Gradient Boosting model initialized")
print("   Parameters:")
print("   n_estimators = 100")
print("   max_depth = 4")
print("   learning_rate = 0.1")

"""Train Gradient Boosting Model"""

# Train model
model_gb.fit(X_train, y_train)

print("\n Gradient Boosting training complete")
print(f"  Trained 100 boosting stages on {len(X_train)} samples")

"""Gradient Boosting Predictions & Metrics"""

# Make predictions
y_pred_train_gb = model_gb.predict(X_train)
y_pred_test_gb = model_gb.predict(X_test)

# Calculate metrics
train_r2_gb = r2_score(y_train, y_pred_train_gb)
train_mae_gb = mean_absolute_error(y_train, y_pred_train_gb)
train_rmse_gb = np.sqrt(mean_squared_error(y_train, y_pred_train_gb))

test_r2_gb = r2_score(y_test, y_pred_test_gb)
test_mae_gb = mean_absolute_error(y_test, y_pred_test_gb)
test_rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_test_gb))

print("\n GRADIENT BOOSTING PERFORMANCE:")
print(f"   TRAINING SET:")
print(f"      R¬≤   = {train_r2_gb:.4f}")
print(f"      MAE  = {train_mae_gb:.3f} MJ/m¬≤")
print(f"      RMSE = {train_rmse_gb:.3f} MJ/m¬≤")

print(f"\n   TESTING SET:")
print(f"      R¬≤   = {test_r2_gb:.4f}")
print(f"      MAE  = {test_mae_gb:.3f} MJ/m¬≤")
print(f"      RMSE = {test_rmse_gb:.3f} MJ/m¬≤")

print(f"\n   Overfitting gap: {train_r2_gb - test_r2_gb:.4f}")

"""Model Comparison Summary"""

import pandas as pd
# Create comparison dataframe
comparison = pd.DataFrame({
    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting'],
    'Train_R2': [train_r2, train_r2_dt, train_r2_rf, train_r2_gb],
    'Test_R2': [test_r2, test_r2_dt, test_r2_rf, test_r2_gb],
    'Test_MAE': [test_mae, test_mae_dt, test_mae_rf, test_mae_gb],
    'Test_RMSE': [test_rmse, test_rmse_dt, test_rmse_rf, test_rmse_gb],
    'Overfitting_Gap': [
        train_r2 - test_r2,
        train_r2_dt - test_r2_dt,
        train_r2_rf - test_r2_rf,
        train_r2_gb - test_r2_gb
    ]
})

# Sort by Test R¬≤
comparison = comparison.sort_values('Test_R2', ascending=False).reset_index(drop=True)

print("\n MODEL PERFORMANCE RANKING (by Test R¬≤):")
print(comparison.to_string(index=False))

# Identify best model
best_model = comparison.iloc[0]['Model']
best_r2 = comparison.iloc[0]['Test_R2']

print("\n" + "="*70)
print(f" BEST MODEL: {best_model}")
print(f"   Test R¬≤ = {best_r2:.4f}")

""" Model Comparison Visualization"""

# Create comparison plot
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: R¬≤ Comparison
x_pos = range(len(comparison))
axes[0].bar(x_pos, comparison['Test_R2'], color='skyblue',
            edgecolor='black', linewidth=1.5, alpha=0.7)
axes[0].set_xlabel('Model', fontsize=12, fontweight='bold')
axes[0].set_ylabel('Test R¬≤ Score', fontsize=12, fontweight='bold')
axes[0].set_title('Model Performance Comparison (R¬≤)',
                  fontsize=13, fontweight='bold')
axes[0].set_xticks(x_pos)
axes[0].set_xticklabels(comparison['Model'], rotation=15, ha='right')
axes[0].grid(True, alpha=0.3, axis='y')

# Add value labels
for i, v in enumerate(comparison['Test_R2']):
    axes[0].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')

# Plot 2: MAE Comparison
axes[1].bar(x_pos, comparison['Test_MAE'], color='coral',
            edgecolor='black', linewidth=1.5, alpha=0.7)
axes[1].set_xlabel('Model', fontsize=12, fontweight='bold')
axes[1].set_ylabel('Test MAE (MJ/m¬≤)', fontsize=12, fontweight='bold')
axes[1].set_title('Model Performance Comparison (MAE)',
                  fontsize=13, fontweight='bold')
axes[1].set_xticks(x_pos)
axes[1].set_xticklabels(comparison['Model'], rotation=15, ha='right')
axes[1].grid(True, alpha=0.3, axis='y')

# Add value labels
for i, v in enumerate(comparison['Test_MAE']):
    axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

plt.tight_layout()
plt.savefig('Model_Comparison.png', dpi=300, bbox_inches='tight')
print("\n Saved: Model_Comparison.png")
plt.show()

"""Confirm Best Model and Prepare for Forecasting"""

print("="*70)
print("CELL: CONFIRM BEST MODEL FOR FORECASTING")
print("="*70)

# Display the best model from comparison
print(f"\nBest Performing Model: Linear Regression")
print(f"  Test R¬≤: {test_r2:.4f}")
print(f"  Test MAE: {test_mae:.3f} MJ/m¬≤")
print(f"  Test RMSE: {test_rmse:.3f} MJ/m¬≤")

print("\nThis model will be used to generate 2026 forecasts.")
print("\n" + "="*70)

"""Create 2026 Forecast Structure"""

# Create forecast for 2026 only (12 months)
forecast_data = []

for month in range(1, 13):
    forecast_data.append({
        'year': 2026,
        'month': month,
        'date': f'2026-{month:02d}-01'
    })

forecast_df = pd.DataFrame(forecast_data)
forecast_df['date'] = pd.to_datetime(forecast_df['date'])

print(f"\n Forecast structure created")
print(f"   Year: 2026")
print(f"   Total months: {len(forecast_df)}")
print(f"   Date range: {forecast_df['date'].min()} to {forecast_df['date'].max()}")

print("="*70)
print("CREATING 2026 FORECAST - CORRECT METHOD")
print("="*70)

# Step 1: Create forecast structure (12 months for 2026)
forecast_data = []

for month in range(1, 13):
    forecast_data.append({
        'year': 2026,
        'month': month,
        'date': f'2026-{month:02d}-01'
    })

forecast_df = pd.DataFrame(forecast_data)
forecast_df['date'] = pd.to_datetime(forecast_df['date'])

print(f"\n‚úÖ Forecast structure created")
print(f"   Year: 2026")
print(f"   Total months: {len(forecast_df)}")
print(f"   Date range: {forecast_df['date'].min()} to {forecast_df['date'].max()}")

# Step 2: Calculate AVERAGE historical patterns per month (THIS IS THE KEY!)
print("\nüìä Calculating historical monthly averages...")
historical_monthly_avg = monthly_data.groupby('month')[feature_columns].mean().reset_index()

print("\n‚úÖ Historical monthly averages calculated:")
print(f"   Shape: {historical_monthly_avg.shape}")  # Should be (12, 6) - 12 months, 5 features + month
print("\nPreview:")
print(historical_monthly_avg.head())

# Step 3: Merge forecast with AVERAGED historical patterns
forecast_df = forecast_df.merge(
    historical_monthly_avg,
    on='month',
    how='left'
)

print(f"\n‚úÖ Historical weather patterns added")
print(f"   Final forecast dataframe shape: {forecast_df.shape}")  # Should be (12, X)
print(f"   Total rows: {len(forecast_df)}")  # Should be 12!

print("\nüìã Forecast data preview:")
print(forecast_df[['date', 'month', 'uvindex', 'cloudcover', 'humidity', 'temp', 'precipcover']])

# Step 4: Prepare features for prediction
X_forecast = forecast_df[feature_columns]

print("\nüéØ Features prepared for prediction:")
print(f"   Shape: {X_forecast.shape}")  # Should be (12, 5)

# Step 5: Make predictions using best model
forecast_df['predicted_solar'] = model_lr.predict(X_forecast)

print("\n‚úÖ Solar energy predictions generated")

# Step 6: Add additional context
month_names = ['January', 'February', 'March', 'April', 'May', 'June',
               'July', 'August', 'September', 'October', 'November', 'December']

forecast_df['month_name'] = [month_names[m-1] for m in forecast_df['month']]

# Step 7: Display results
print("\n" + "="*70)
print("2026 MONTHLY FORECASTS")
print("="*70)
for idx, row in forecast_df.iterrows():
    print(f"  {row['month_name']:12s} 2026: {row['predicted_solar']:5.2f} MJ/m¬≤")
# Summary statistics
print("\n" + "="*70)
print("2026 SUMMARY STATISTICS")
print("="*70)
mean_2026 = forecast_df['predicted_solar'].mean()
min_2026 = forecast_df['predicted_solar'].min()
max_2026 = forecast_df['predicted_solar'].max()
min_month = forecast_df.loc[forecast_df['predicted_solar'].idxmin(), 'month_name']
max_month = forecast_df.loc[forecast_df['predicted_solar'].idxmax(), 'month_name']

print(f"  Mean:   {mean_2026:.2f} MJ/m¬≤")
print(f"  Min:    {min_2026:.2f} MJ/m¬≤ ({min_month})")
print(f"  Max:    {max_2026:.2f} MJ/m¬≤ ({max_month})")
print(f"  Range:  {max_2026 - min_2026:.2f} MJ/m¬≤")
print(f"  Std:    {forecast_df['predicted_solar'].std():.2f} MJ/m¬≤")

# Step 8: Save to CSV
forecast_df.to_csv('Forecast_2026_Colombo04.csv', index=False)

print("\n" + "="*70)
print("‚úÖ FORECAST SAVED")
print("="*70)
print(f"   File: Forecast_2026_Colombo04.csv")
print(f"   Rows: {len(forecast_df)} (should be 12!)")
print(f"   Columns: {len(forecast_df.columns)}")
print("="*70)

# Verify the CSV
print("\nüîç CSV VERIFICATION:")
test_read = pd.read_csv('Forecast_2026_Colombo04.csv')
print(f"   CSV contains {len(test_read)} rows ‚úÖ" if len(test_read) == 12 else f"   ‚ö†Ô∏è WARNING: CSV has {len(test_read)} rows instead of 12!")

print("\n" + "="*70)

"""Predict Solar Energy for 2026"""

# Prepare features for prediction
X_forecast = forecast_df[feature_columns]

# Use Linear Regression (best model) to predict
forecast_df['predicted_solar'] = model_lr.predict(X_forecast)

print("\n Solar energy predictions generated")
print(f"  Total predictions: {len(forecast_df)} months")

print("\n 2026 MONTHLY FORECASTS:")
month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

for idx, row in forecast_df.iterrows():
    month_name = month_names[row['month']-1]
    print(f"   {month_name} 2026: {row['predicted_solar']:5.2f} MJ/m¬≤")

# Summary statistics
mean_2026 = forecast_df['predicted_solar'].mean()
min_2026 = forecast_df['predicted_solar'].min()
max_2026 = forecast_df['predicted_solar'].max()

print("\n 2026 SUMMARY:")
print(f"   Mean:  {mean_2026:.2f} MJ/m¬≤")
print(f"   Min:   {min_2026:.2f} MJ/m¬≤ ({month_names[forecast_df.loc[forecast_df['predicted_solar'].idxmin(), 'month'] - 1]}) ")
print(f"   Max:   {max_2026:.2f} MJ/m¬≤ ({month_names[forecast_df.loc[forecast_df['predicted_solar'].idxmax(), 'month'] - 1]}) ")

"""Add Month Names and Seasons"""

# Add month names
month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
forecast_df['month_name'] = forecast_df['month'].apply(lambda x: month_names[x-1])

# Add seasons
def assign_season(month):
    if month in [12, 1, 2]:
        return 'NE Monsoon'
    elif month in [3, 4]:
        return 'Inter-Monsoon 1'
    elif month in [5, 6, 7, 8, 9]:
        return 'SW Monsoon'
    else:
        return 'Inter-Monsoon 2'

forecast_df['season'] = forecast_df['month'].apply(assign_season)

print("\n Month names and seasons added")

print("\n Complete forecast preview:")
print(forecast_df[['date', 'month_name', 'season', 'predicted_solar']].to_string(index=False))

"""Visual on the focast"""

# Create forecast visualization
fig, axes = plt.subplots(2, 1, figsize=(14, 10))

# Plot 1: Historical + Forecast
axes[0].plot(monthly_data['date'], monthly_data['solarenergy'],
             'o-', linewidth=2, markersize=5, color='orange',
             label='Historical (2021-2025)', alpha=0.8)
axes[0].plot(forecast_df['date'], forecast_df['predicted_solar'],
             's--', linewidth=2, markersize=6, color='blue',
             label='Forecast (2026)', alpha=0.8)
axes[0].axvline(x=pd.Timestamp('2026-01-01'), color='red',
                linestyle=':', linewidth=2, alpha=0.5)
axes[0].text(pd.Timestamp('2026-06-01'), axes[0].get_ylim()[1]*0.95,
             'Forecast Period', fontsize=11, ha='center', color='red')

axes[0].set_xlabel('Date', fontsize=12, fontweight='bold')
axes[0].set_ylabel('Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
axes[0].set_title('Historical Data + 2026 Forecast',
                  fontsize=14, fontweight='bold')
axes[0].legend(fontsize=11)
axes[0].grid(True, alpha=0.3)
axes[0].tick_params(axis='x', rotation=45)

# Plot 2: 2026 Monthly Forecast
axes[1].bar(forecast_df['month'], forecast_df['predicted_solar'],
            color='skyblue', edgecolor='black', linewidth=1.5, alpha=0.7)
axes[1].set_xlabel('Month', fontsize=12, fontweight='bold')
axes[1].set_ylabel('Predicted Solar Energy (MJ/m¬≤)', fontsize=12, fontweight='bold')
axes[1].set_title('2026 Monthly Solar Energy Forecast',
                  fontsize=14, fontweight='bold')
axes[1].set_xticks(range(1, 13))
axes[1].set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                         'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('2026_Forecast.png', dpi=300, bbox_inches='tight')
print("\n Saved: 2026_Forecast.png")
plt.show()

"""Save 2026 Forecast Data"""

# Save forecast to CSV
forecast_df.to_csv('Forecast_2026_Colombo04.csv', index=False)

print("\n Saved: Forecast_2026_Colombo04.csv")

print("\n FORECAST SUMMARY:")
print(f"   Year: 2026")
print(f"   Months: {len(forecast_df)}")
print(f"   Mean Solar: {forecast_df['predicted_solar'].mean():.2f} MJ/m¬≤")
print(f"   Min Solar: {forecast_df['predicted_solar'].min():.2f} MJ/m¬≤")
print(f"   Max Solar: {forecast_df['predicted_solar'].max():.2f} MJ/m¬≤")

# AUTO-ADD HISTORICAL SOLAR DATA

# Load forecast from CSV
import pandas as pd

try:
    print("‚úÖ Using existing forecast_df")
    # No 'pass' needed here; execution continues
except NameError:
    forecast_df = pd.read_csv('Forecast_2026_Colombo04.csv')
    print("‚úÖ Loaded from CSV")

# Remove any existing historical columns from a previous run before re-joining
cols_to_drop = [col for col in forecast_df.columns if col.startswith('historical_')]
if cols_to_drop:
    forecast_df = forecast_df.drop(columns=cols_to_drop)
    print(f"‚úÖ Dropped existing historical columns: {cols_to_drop}")


# Calculate historical statistics
historical_solar_stats = monthly_data.groupby('month')['solarenergy'].agg([
    ('historical_avg', 'mean'),
    ('historical_std', 'std'),
    ('historical_min', 'min'),
    ('historical_max', 'max')
]).reset_index()

print(f"‚úÖ Calculated historical stats for {len(historical_solar_stats)} months")

# Merge with forecast using set_index().join() for robustness
# This ensures that 'month' is the key for joining
forecast_df = forecast_df.set_index('month').join(historical_solar_stats.set_index('month'), how='left').reset_index()

# Add comparison columns
forecast_df['difference_from_historical'] = (
    forecast_df['predicted_solar'] - forecast_df['historical_avg']
).round(2)

forecast_df['percent_difference'] = (
    (forecast_df['difference_from_historical'] / forecast_df['historical_avg']) * 100
).round(1)

# Save enhanced CSV
forecast_df.to_csv('Forecast_2026_with_Historical.csv', index=False)


# Display results
display_cols = ['month_name', 'predicted_solar', 'historical_avg', 'difference_from_historical']
print(forecast_df[display_cols].to_string(index=False))

from google.colab import files

# Download the forecast CSV
files.download('Forecast_2026_Colombo04.csv')